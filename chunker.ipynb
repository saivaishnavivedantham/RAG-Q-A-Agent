{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4dd35-7a69-442e-a051-43fd58dc429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re # Import the regular expression module\n",
    "\n",
    "# Configuration\n",
    "data_dir = Path(\"data/extracted\") # Directory where extracted .txt files are located\n",
    "chunk_output_dir = Path(\"chunks\") # Directory to save the chunked JSON\n",
    "chunk_output_dir.mkdir(parents=True, exist_ok=True) # Ensure output directory exists\n",
    "\n",
    "def split_into_chunks(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"\n",
    "    Splits text into chunks with a specified size and overlap.\n",
    "    A simple character-based chunking for demonstration.\n",
    "    For real-world RAG, consider more sophisticated methods (e.g., sentence-based, semantic chunking).\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += (chunk_size - overlap) # Move start for next chunk\n",
    "        if start >= len(text): # Ensure loop terminates if end reaches or passes text length\n",
    "            break\n",
    "    return chunks\n",
    "\n",
    "def run_chunker():\n",
    "    \"\"\"\n",
    "    Orchestrates the chunking process for all extracted text files,\n",
    "    adding company and year metadata.\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    files_processed_count = 0\n",
    "    chunks_generated_count = 0\n",
    "\n",
    "    print(f\"Ensured output directory '{chunk_output_dir.resolve()}' exists.\")\n",
    "    print(\"\\nStarting chunking process...\")\n",
    "\n",
    "    for txt_file in data_dir.glob(\"*.txt\"):\n",
    "        files_processed_count += 1\n",
    "        with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Extract company ticker and year from filename using regex\n",
    "        # Assuming filenames are like 'GOOGL_2022_10K.txt'\n",
    "        match = re.match(r\"([A-Z]+)_(\\d{4})_10K\\.txt\", txt_file.name)\n",
    "        company_ticker = match.group(1) if match else \"N/A\"\n",
    "        fiscal_year = match.group(2) if match else \"N/A\"\n",
    "\n",
    "        chunks = split_into_chunks(content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            all_chunks.append({\n",
    "                \"source_file\": txt_file.name,\n",
    "                \"chunk_id\": f\"{txt_file.stem}_chunk_{i}\",\n",
    "                \"text\": chunk,\n",
    "                \"company\": company_ticker, # ADDED: Company ticker\n",
    "                \"year\": fiscal_year      # ADDED: Fiscal year\n",
    "            })\n",
    "            chunks_generated_count += 1\n",
    "        print(f\"  Processed {txt_file.name} -> Generated {len(chunks)} chunks.\")\n",
    "\n",
    "    # Save all chunks to a single JSON file\n",
    "    with open(chunk_output_dir / \"all_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_chunks, f, indent=2)\n",
    "\n",
    "    print(f\"\\nFinished chunking process. Total files processed: {files_processed_count}, Total chunks generated: {chunks_generated_count}\")\n",
    "    print(f\"Saved all chunks to {chunk_output_dir.resolve() / 'all_chunks.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772342cf-e785-448a-8a86-679b0c8bf18f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
