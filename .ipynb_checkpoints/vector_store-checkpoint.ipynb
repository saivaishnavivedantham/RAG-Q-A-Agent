{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c8635-db77-45a2-a78b-a3271e8c3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define input directory for embeddings and output for vector store index (optional, but good practice)\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "# Input: Chunks with embeddings from the embedder.ipynb\n",
    "INPUT_FILE_ALL_EMBEDDINGS = os.path.join(PROJECT_ROOT, \"embeddings\", \"all_chunks_with_embeddings.json\")\n",
    "# Output: Directory to save the FAISS index (optional, for persistence)\n",
    "OUTPUT_DIR_VECTOR_STORE = os.path.join(PROJECT_ROOT, \"vector_store\")\n",
    "FAISS_INDEX_FILE = os.path.join(OUTPUT_DIR_VECTOR_STORE, \"faiss_index.bin\")\n",
    "\n",
    "# Configuration for the embedding model (same as in embedder.ipynb)\n",
    "EMBEDDING_MODEL_NAME = 'all-MiniLM-L12-v2'\n",
    "embedding_model = None # Will be loaded once for query embedding\n",
    "\n",
    "def create_output_directory():\n",
    "    \"\"\"Creates the output directory for the vector store if it doesn't exist.\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR_VECTOR_STORE, exist_ok=True)\n",
    "    print(f\"Ensured output directory '{OUTPUT_DIR_VECTOR_STORE}' exists.\")\n",
    "\n",
    "def load_embedding_model_for_query():\n",
    "    \"\"\"Loads the SentenceTransformer model globally for query embedding.\"\"\"\n",
    "    global embedding_model\n",
    "    if embedding_model is None:\n",
    "        print(f\"Loading embedding model for queries: {EMBEDDING_MODEL_NAME}...\")\n",
    "        try:\n",
    "            embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "            print(\"Query embedding model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading query embedding model {EMBEDDING_MODEL_NAME}: {e}\")\n",
    "            print(\"Please ensure you have an active internet connection or the model is cached locally.\")\n",
    "            embedding_model = None\n",
    "    return embedding_model\n",
    "\n",
    "class VectorStore:\n",
    "    \"\"\"\n",
    "    A simple in-memory vector store using FAISS for efficient similarity search.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.index = None\n",
    "        self.chunk_data = [] # Stores the original chunk information (text, metadata)\n",
    "        self.dimension = 0\n",
    "\n",
    "    def load_data_and_build_index(self, json_filepath):\n",
    "        \"\"\"\n",
    "        Loads chunk data with embeddings from a JSON file and builds the FAISS index.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(json_filepath):\n",
    "            print(f\"Error: Input file '{json_filepath}' not found. Please ensure embedder.main() has run successfully.\")\n",
    "            return False\n",
    "\n",
    "        print(f\"Loading chunks and embeddings from '{json_filepath}'...\")\n",
    "        try:\n",
    "            with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "                self.chunk_data = json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to load JSON from '{json_filepath}': {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading '{json_filepath}': {e}\")\n",
    "            return False\n",
    "\n",
    "        if not self.chunk_data:\n",
    "            print(\"No chunk data found to build the index.\")\n",
    "            return False\n",
    "\n",
    "        # Extract embeddings and ensure they are floats\n",
    "        embeddings_list = [np.array(item[\"embedding\"], dtype=np.float32) for item in self.chunk_data if \"embedding\" in item and item[\"embedding\"] is not None]\n",
    "\n",
    "        if not embeddings_list:\n",
    "            print(\"No embeddings found in the data. Cannot build FAISS index.\")\n",
    "            return False\n",
    "\n",
    "        # All embeddings must have the same dimension\n",
    "        self.dimension = embeddings_list[0].shape[0]\n",
    "        embeddings_matrix = np.array(embeddings_list)\n",
    "\n",
    "        print(f\"Building FAISS index with {len(embeddings_matrix)} vectors of dimension {self.dimension}...\")\n",
    "        \n",
    "        # Using IndexFlatL2 for a simple L2 (Euclidean distance) index\n",
    "        # This is a basic but effective index for similarity search.\n",
    "        self.index = faiss.IndexFlatL2(self.dimension)\n",
    "        self.index.add(embeddings_matrix) # Add the embeddings to the index\n",
    "\n",
    "        print(\"FAISS index built successfully.\")\n",
    "        return True\n",
    "\n",
    "    def search(self, query_text, k=5):\n",
    "        \"\"\"\n",
    "        Performs a similarity search in the vector store for a given query.\n",
    "\n",
    "        Args:\n",
    "            query_text (str): The text query to search for.\n",
    "            k (int): The number of top relevant chunks to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries, where each dictionary contains\n",
    "                  the original chunk information and its similarity score.\n",
    "        \"\"\"\n",
    "        if self.index is None:\n",
    "            print(\"Vector store index not built. Please load data first.\")\n",
    "            return []\n",
    "        if load_embedding_model_for_query() is None:\n",
    "            print(\"Query embedding model not loaded. Cannot perform search.\")\n",
    "            return []\n",
    "\n",
    "        print(f\"Generating embedding for query: '{query_text}'...\")\n",
    "        query_embedding = embedding_model.encode(query_text, convert_to_numpy=True).astype(np.float32)\n",
    "        \n",
    "        # Ensure query embedding has the correct dimension\n",
    "        if query_embedding.shape[0] != self.dimension:\n",
    "            print(f\"Error: Query embedding dimension ({query_embedding.shape[0]}) does not match index dimension ({self.dimension}).\")\n",
    "            return []\n",
    "\n",
    "        # Reshape for FAISS: needs to be 2D array (1, dimension)\n",
    "        query_embedding = query_embedding.reshape(1, -1)\n",
    "\n",
    "        print(f\"Searching for top {k} similar chunks...\")\n",
    "        # D: distances (lower is more similar for L2), I: indices of top-k vectors\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "\n",
    "        results = []\n",
    "        for i, idx in enumerate(indices[0]):\n",
    "            if idx == -1: # FAISS returns -1 if not enough results\n",
    "                continue\n",
    "            chunk = self.chunk_data[idx]\n",
    "            score = distances[0][i]\n",
    "            results.append({\n",
    "                \"chunk\": chunk,\n",
    "                \"similarity_score\": float(score) # Convert numpy float to Python float for JSON serialization\n",
    "            })\n",
    "        print(f\"Found {len(results)} relevant chunks.\")\n",
    "        return results\n",
    "\n",
    "    def save_index(self, filepath=FAISS_INDEX_FILE):\n",
    "        \"\"\"Saves the FAISS index to disk for persistence.\"\"\"\n",
    "        create_output_directory()\n",
    "        if self.index:\n",
    "            try:\n",
    "                faiss.write_index(self.index, filepath)\n",
    "                print(f\"FAISS index saved to '{filepath}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving FAISS index: {e}\")\n",
    "        else:\n",
    "            print(\"No index to save.\")\n",
    "\n",
    "    def load_index(self, filepath=FAISS_INDEX_FILE):\n",
    "        \"\"\"Loads a FAISS index from disk.\"\"\"\n",
    "        if os.path.exists(filepath):\n",
    "            try:\n",
    "                self.index = faiss.read_index(filepath)\n",
    "                # Reconstruct chunk_data if needed for search results (depends on use case)\n",
    "                # For this simple example, we assume chunk_data is loaded separately with build_index or always kept in memory\n",
    "                print(f\"FAISS index loaded from '{filepath}'\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading FAISS index from '{filepath}': {e}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"FAISS index file not found at '{filepath}'\")\n",
    "            return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate vector store functionality.\"\"\"\n",
    "    create_output_directory()\n",
    "    vector_store = VectorStore()\n",
    "\n",
    "    # Build the index from the embeddings JSON file\n",
    "    if vector_store.load_data_and_build_index(INPUT_FILE_ALL_EMBEDDINGS):\n",
    "        # Example Usage: Perform a search\n",
    "        sample_query = \"What was Microsoft's total revenue in 2023?\"\n",
    "        retrieved_chunks = vector_store.search(sample_query, k=3)\n",
    "\n",
    "        print(\"\\n--- Retrieved Chunks for Sample Query ---\")\n",
    "        if retrieved_chunks:\n",
    "            for i, result in enumerate(retrieved_chunks):\n",
    "                chunk = result['chunk']\n",
    "                score = result['similarity_score']\n",
    "                print(f\"\\nResult {i+1} (Score: {score:.4f}):\")\n",
    "                print(f\"  Company: {chunk.get('company', 'N/A')}, Year: {chunk.get('year', 'N/A')}\")\n",
    "                print(f\"  Source File: {chunk.get('source_file', 'N/A')}\")\n",
    "                print(f\"  Chunk ID: {chunk.get('id', 'N/A')}\")\n",
    "                print(f\"  Text (first 200 chars): {chunk.get('text', '')[:200]}...\")\n",
    "        else:\n",
    "            print(\"No chunks retrieved.\")\n",
    "        \n",
    "        # Optional: Save the FAISS index to disk for later use without re-building\n",
    "        vector_store.save_index()\n",
    "    else:\n",
    "        print(\"Failed to initialize vector store. Check previous errors.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
