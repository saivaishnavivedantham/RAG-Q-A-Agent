{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45178d92-ced0-4335-965f-8562c1be0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Configuration\n",
    "chunk_path = Path(\"chunks/all_chunks.json\") # Input file from chunker\n",
    "output_path = Path(\"data\") # Output directory for embedded_chunks.json\n",
    "embedded_file = output_path / \"embedded_chunks.json\" # Output file for embeddings\n",
    "\n",
    "def run_embedder():\n",
    "    \"\"\"\n",
    "    Loads text chunks, generates embeddings using SentenceTransformer,\n",
    "    and saves them to a JSON file.\n",
    "    \"\"\"\n",
    "    if not chunk_path.exists():\n",
    "        print(f\"Error: Chunks file not found at {chunk_path}. Please run chunker.ipynb first.\")\n",
    "        return\n",
    "\n",
    "    with open(chunk_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(chunks)} chunks from {chunk_path}\")\n",
    "\n",
    "    # Initializing the SentenceTransformer model\n",
    "    # \"all-MiniLM-L6-v2\" is a good balance of speed and performance.\n",
    "    # Consider \"all-mpnet-base-v2\" for potentially better quality, but slower.\n",
    "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    print(\"Embedding with SentenceTransformer...\")\n",
    "\n",
    "    embedded_chunks = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            # Encode the text to get its embedding\n",
    "            # .tolist() is necessary here to make the numpy array JSON serializable\n",
    "            embedding = embed_model.encode(chunk[\"text\"]).tolist()\n",
    "            chunk[\"embedding\"] = embedding\n",
    "            embedded_chunks.append(chunk)\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(chunks)} chunks...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding chunk {chunk.get('chunk_id', i)}: {e}\")\n",
    "            # Optionally, skip chunk or add a placeholder embedding\n",
    "            chunk[\"embedding\"] = None # Indicate failure\n",
    "            embedded_chunks.append(chunk)\n",
    "\n",
    "\n",
    "    with open(embedded_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(embedded_chunks, f, indent=2)\n",
    "\n",
    "    print(f\" Saved embedded chunks to {embedded_file}\")\n",
    "    print(f\"Total embedded chunks: {len(embedded_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75ac64-1b44-4b6d-9d02-29810deabf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
